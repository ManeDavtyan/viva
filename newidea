import pandas as pd
import re
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

# Assuming df is your DataFrame and 'HttpHost' is the column of interest
df['HttpHost'] = df['HttpHost'].astype(str)  # Ensure the column is of string type

# Vectorize HTTP hosts using TF-IDF
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(df['HttpHost'])

# Perform k-means clustering
num_clusters = 10
kmeans = KMeans(n_clusters=num_clusters, random_state=42)
df['Cluster'] = kmeans.fit_predict(X)

# Use PCA for dimensionality reduction
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X.toarray())

# Plotting cluster assignments
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=df['Cluster'], cmap='viridis', s=20)
plt.title('K-Means Clustering of HTTP Hosts')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.show()

# Display the distribution of HTTP hosts in each cluster
cluster_distribution = df.groupby('Cluster')['HttpHost'].value_counts()
print("Cluster Distribution:")
print(cluster_distribution)

# Print each row with its cluster assignment
for index, row in df.iterrows():
    print(f"Row {index}: Cluster {row['Cluster']} - HTTP Host: {row['HttpHost']}")



#Hierarchial Clustering
import pandas as pd
import re
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import AgglomerativeClustering
from scipy.cluster.hierarchy import dendrogram, linkage

# Assuming df is your DataFrame and 'HttpHost' is the column of interest
df['HttpHost'] = df['HttpHost'].astype(str)

# Vectorize HTTP hosts using TF-IDF
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(df['HttpHost'])

# Perform hierarchical clustering
agg_clustering = AgglomerativeClustering(n_clusters=10, linkage='ward')
df['Cluster'] = agg_clustering.fit_predict(X.toarray())

# Plot hierarchical clustering dendrogram
linked = linkage(X.toarray(), 'ward')
dendrogram(linked, orientation='top', distance_sort='descending', show_leaf_counts=True)
plt.title('Hierarchical Clustering Dendrogram')
plt.xlabel('Sample Index')
plt.ylabel('Distance')
plt.show()

# Evaluate clustering
silhouette_avg = silhouette_score(X, df['Cluster'])
print(f"Silhouette Score: {silhouette_avg}")

#DBSCAN 

import pandas as pd
import re
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import DBSCAN
from sklearn.metrics import silhouette_score

# Assuming df is your DataFrame and 'HttpHost' is the column of interest
df['HttpHost'] = df['HttpHost'].astype(str)

# Vectorize HTTP hosts using TF-IDF
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(df['HttpHost'])

# Perform DBSCAN clustering
dbscan = DBSCAN(eps=0.5, min_samples=5)
df['Cluster'] = dbscan.fit_predict(X)

# Evaluate clustering
silhouette_avg = silhouette_score(X, df['Cluster'])
print(f"Silhouette Score: {silhouette_avg}")


# GMM 

import pandas as pd
import re
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.mixture import GaussianMixture
from sklearn.metrics import silhouette_score

# Assuming df is your DataFrame and 'HttpHost' is the column of interest
df['HttpHost'] = df['HttpHost'].astype(str)

# Vectorize HTTP hosts using TF-IDF
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(df['HttpHost'])

# Perform GMM clustering
gmm = GaussianMixture(n_components=10, random_state=42)
df['Cluster'] = gmm.fit_predict(X.toarray())

# Evaluate clustering
silhouette_avg = silhouette_score(X, df['Cluster'])
print(f"Silhouette Score: {silhouette_avg}")





#Feature Engineering 

import pandas as pd
import re
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

# Assuming df is your DataFrame and 'HttpHost' is the column of interest
df['HttpHost'] = df['HttpHost'].astype(str)

# Feature Engineering
import pandas as pd
import re
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

# Assuming df is your DataFrame and 'HttpHost' is the column of interest
df['HttpHost'] = df['HttpHost'].astype(str)

# Feature Engineering
# Example: Extracting Length and Count of Digits
df['Length'] = df['HttpHost'].apply(len)
df['DigitCount'] = df['HttpHost'].apply(lambda x: sum(c.isdigit() for c in x))

# Additional feature ideas:
# - Count of special characters
# - Presence of specific keywords or patterns
# - Using domain-specific knowledge to create relevant features

# Check if the number of clusters is greater than or equal to the number of samples
num_clusters = 10
if len(df) >= num_clusters:
    # Vectorize HTTP hosts and additional features using TF-IDF
    vectorizer = TfidfVectorizer()
    X = vectorizer.fit_transform(df[['HttpHost', 'Length', 'DigitCount']].astype(str))

    # Perform k-means clustering
    kmeans = KMeans(n_clusters=num_clusters, random_state=42)
    df['Cluster'] = kmeans.fit_predict(X)

    # Use PCA for dimensionality reduction
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(X.toarray())

    # Plotting cluster assignments
    plt.scatter(X_pca[:, 0], X_pca[:, 1], c=df['Cluster'], cmap='viridis', s=20)
    plt.title('K-Means Clustering of HTTP Hosts with Engineered Features')
    plt.xlabel('Principal Component 1')
    plt.ylabel('Principal Component 2')
    plt.show()

    # Display the distribution of HTTP hosts in each cluster
    cluster_distribution = df.groupby('Cluster')['HttpHost'].value_counts()
    print("Cluster Distribution:")
    print(cluster_distribution)

    # Print each row with its cluster assignment
    for index, row in df.iterrows():
        print(f"Row {index}: Cluster {row['Cluster']} - HTTP Host: {row['HttpHost']} - Length: {row['Length']} - DigitCount: {row['DigitCount']}")
else:
    print("Number of samples is less than the number of clusters. Please adjust the number of clusters or acquire more data.")





#last

import pandas as pd
import re
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

# Assuming df is your DataFrame and 'HttpHost' is the column of interest
df['HttpHost'] = df['HttpHost'].astype(str)

# Feature Engineering
# Example: Extracting Length and Count of Digits
df['Length'] = df['HttpHost'].apply(len)
df['DigitCount'] = df['HttpHost'].apply(lambda x: sum(c.isdigit() for c in x))

# Additional feature ideas:
# - Count of special characters
# - Presence of specific keywords or patterns
# - Using domain-specific knowledge to create relevant features

# Check the number of clusters based on the number of samples
num_clusters = min(10, len(df))

# Vectorize HTTP hosts and additional features using TF-IDF
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(df[['HttpHost', 'Length', 'DigitCount']].astype(str))

# Perform k-means clustering
kmeans = KMeans(n_clusters=num_clusters, random_state=42)
df['Cluster'] = kmeans.fit_predict(X)

# Use PCA for dimensionality reduction
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X.toarray())

# Plotting cluster assignments
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=df['Cluster'], cmap='viridis', s=20)
plt.title('K-Means Clustering of HTTP Hosts with Engineered Features')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.show()

# Display the distribution of HTTP hosts in each cluster
cluster_distribution = df.groupby('Cluster')['HttpHost'].value_counts()
print("Cluster Distribution:")
print(cluster_distribution)

# Print each row with its cluster assignment
for index, row in df.iterrows():
    print(f"Row {index}: Cluster {row['Cluster']} - HTTP Host: {row['HttpHost']} - Length: {row['Length']} - DigitCount: {row['DigitCount']}")

